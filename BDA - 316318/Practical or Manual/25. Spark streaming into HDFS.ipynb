{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ö° Store Real-Time Streamed Data from Spark Streaming into HDFS\n",
        "\n",
        "This guide shows how to **capture live streaming data** using Spark Streaming and **save it to HDFS** at regular intervals.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Step 1: Start a Socket Stream\n",
        "\n",
        "Run this in a terminal:\n",
        "\n",
        "```bash\n",
        "nc -lk 9999\n",
        "````\n",
        "\n",
        "This creates a simple text stream on port **9999**.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Step 2: Spark Streaming Script to Save Data to HDFS\n",
        "\n",
        "Create a Spark Streaming application (`SaveToHDFS.scala`):\n",
        "\n",
        "```scala\n",
        "import org.apache.spark.SparkConf\n",
        "import org.apache.spark.streaming.{Seconds, StreamingContext}\n",
        "\n",
        "object SaveToHDFS {\n",
        "  def main(args: Array[String]): Unit = {\n",
        "\n",
        "    val conf = new SparkConf().setAppName(\"SaveStreamToHDFS\").setMaster(\"local[*]\")\n",
        "    val ssc = new StreamingContext(conf, Seconds(5))\n",
        "\n",
        "    // Connect to socket stream\n",
        "    val lines = ssc.socketTextStream(\"localhost\", 9999)\n",
        "\n",
        "    // Save each batch to HDFS\n",
        "    lines.saveAsTextFiles(\"hdfs://<namenode>:9000/user/stream/output/streamdata\", \"txt\")\n",
        "\n",
        "    ssc.start()\n",
        "    ssc.awaitTermination()\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ñ∂Ô∏è Step 3: Run the Spark Streaming App\n",
        "\n",
        "```bash\n",
        "spark-submit --class SaveToHDFS SaveToHDFS.jar\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üî• Output\n",
        "\n",
        "* Spark collects streaming data every **5 seconds**\n",
        "* Each batch is stored into HDFS at:\n",
        "\n",
        "```\n",
        "/user/stream/output/streamdata-<timestamp>.txt\n",
        "```\n"
      ],
      "metadata": {
        "id": "i4fIX5U_E2G5"
      }
    }
  ]
}