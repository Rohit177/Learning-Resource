# Perform Basic File Operations using HDFS

### Prerequisites
Make Hadoop cluster is running:
```bash
jps
# Should list NameNode, DataNode, etc.
```

---

### 1. Create Directories and Files

**Create a Directory:**
```bash
# Create a user directory
hdfs dfs -mkdir -p /user/hadoop/practical

# Verify creation
hdfs dfs -ls /user/hadoop/

```

**Or create a File (Empty):**

```bash
hdfs dfs -touchz /user/hadoop/practical/empty_file.txt

```

---

### 2. Read, Write, Update, Delete Operations

#### A. Write (Upload)

1. **Create a local file first:**
```bash
echo "Hello HDFS. Line 1" > local_data.txt

```


2. **Upload to HDFS:**
```bash
# Syntax: hdfs dfs -put <source_local> <dest_hdfs>
hdfs dfs -put local_data.txt /user/hadoop/practical/

```



#### B. Read (View Content)

```bash
hdfs dfs -cat /user/hadoop/practical/local_data.txt

```

#### C. Update (Append)

1. **Create new local data:**
```bash
echo "Line 2 (Appended)." > more_data.txt

```


2. **Append to the existing HDFS file:**
```bash
hdfs dfs -appendToFile more_data.txt /user/hadoop/practical/local_data.txt

```


3. **Verify the update:**
```bash
hdfs dfs -cat /user/hadoop/practical/local_data.txt

```



#### D. Delete

```bash
# Remove a file
hdfs dfs -rm /user/hadoop/practical/empty_file.txt

# Remove a directory (and everything inside it) recursively
# hdfs dfs -rm -r /path/to/directory

```

---

### 3. Set Directory Permissions

**Change Permissions (chmod):**

```bash
# Give Read, Write, Execute to Owner, Read-Execute to Group/Others (755)
hdfs dfs -chmod 755 /user/hadoop/practical/local_data.txt

```

**Change Ownership (chown):**

```bash
# Change owner to 'hadoop' and group to 'supergroup'
hdfs dfs -chown hadoop:supergroup /user/hadoop/practical/local_data.txt

```

---

### 4. Verify File Replication

By default, HDFS replicates files 3 times (on a standard cluster) or 1 time (on a single-node setup).

**Check Current Replication:**
```bash
hdfs dfs -ls /user/hadoop/practical/

```

*Output Example:*
`-rw-r--r--   1 hadoop supergroup ...` (The `1` indicates replication factor).

```bash
# Set replication to 3 (Requires at least 3 DataNodes to take full effect)
hdfs dfs -setrep -w 3 /user/hadoop/practical/local_data.txt

```
