### 1. Configure Hadoop

#### a) Navigate to hadoop

```bash
cd $HADOOP_HOME/etc/hadoop
```
---

#### b) Configure core-site.xml

```bash
nano $HADOOP_HOME/etc/hadoop/core-site.xml
```

```xml
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost:9000</value>
  </property>
</configuration>
```

---

#### c) Configure hdfs-site.xml

```bash
nano $HADOOP_HOME/etc/hadoop/hdfs-site.xml
```

```xml
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
</configuration>
```

---

#### d) Configure mapred-site.xml

```bash
cp $HADOOP_HOME/etc/hadoop/mapred-site.xml.template \
   $HADOOP_HOME/etc/hadoop/mapred-site.xml
nano $HADOOP_HOME/etc/hadoop/mapred-site.xml
```

```xml
<configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
</configuration>
```

---

#### e) Configure yarn-site.xml

```bash
nano $HADOOP_HOME/etc/hadoop/yarn-site.xml
```

```xml
<configuration>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
</configuration>
```

---

### 2. Initialize and Start HDFS

#### **A. Format the NameNode**

**Warning:** Only run this **once** during the initial setup. It clears the file system.

```bash
hdfs namenode -format

```

#### **B. Start HDFS Daemons**

Run the script to start NameNode, DataNode, and Secondary NameNode.

```bash
start-dfs.sh

```

#### **C. Verify Daemons**

Check if processes are running using Java Process Status.

```bash
jps

```

**Expected Output:**

```text
NameNode
DataNode
SecondaryNameNode
Jps

```

---

### 3. Upload Dataset to HDFS

#### **A. Create a Local Dataset**

Create a simple text file to test.

```bash
echo "Hello Hadoop World" > test_data.txt

```

#### **B. Create a Directory in HDFS**

Create a folder named `input` inside HDFS.

```bash
hdfs dfs -mkdir -p /user/hadoop/input

```

#### **C. Upload the File**

Copy the local file to the HDFS directory.

```bash
hdfs dfs -put test_data.txt /user/hadoop/input/

```

#### **D. Verify the Upload**

List the files in the HDFS directory to confirm.

```bash
hdfs dfs -ls /user/hadoop/input/

```

**Expected Output:**

```text
Found 1 items
-rw-r--r--   1 hadoop supergroup         19 2025-12-27 12:00 /user/hadoop/input/test_data.txt

```
