
### **1. Access Hadoop Monitoring Interfaces**

* **Start Services:**
* Ensure Hadoop is running: `start-all.cmd`.
<br>

* **Web UI Access (Browser):**
* **HDFS (NameNode):** Open `http://localhost:9870`
* **YARN (ResourceManager):** Open `http://localhost:8088`
<br>

* **CLI Access (Command Prompt):**
* Open a new Command Prompt (cmd) as Administrator.
<br>


### **2. Locate Resource Usage Indicators**

* **Disk Usage (HDFS UI - localhost:9870):**
* Go to **Overview** tab.
* Look for **"Configured Capacity"** (Total Space).
* Look for **"DFS Used"** (Space taken by Hadoop).
* Look for **"Live Nodes"** (Should be "1" for local setup).
<br>

* **CPU & Memory (YARN UI - localhost:8088):**
* Look at the top cluster metrics table.
* **"Memory Used"**: RAM currently consumed by jobs.
* **"VCores Used"**: CPU cores currently active.
* **"Scheduler"**: Shows the queue of running jobs.
<br>


### **3. Run Basic Monitoring Commands**

Run these in your Command Prompt to check status via text.

* **Check Running Processes:**
* Command: `jps`
* **Expect:** `NameNode`, `DataNode`, `ResourceManager`, `NodeManager`.
<br>

* **Check Disk Health:**
* Command: `hdfs dfsadmin -report`
* **Output:** Detailed breakdown of configured capacity and DFS used.
<br>

* **Check Node Status:**
* Command: `yarn node -list`
* **Output:** Status of the NodeManager (RUNNING/UNHEALTHY).
<br>

* **Check Running Applications:**
* Command: `yarn application -list`
* **Output:** List of currently executing MapReduce jobs.
<br>


