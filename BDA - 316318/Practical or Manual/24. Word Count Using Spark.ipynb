{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ö° Real-Time Word Count Using Spark Streaming\n",
        "\n",
        "Spark Streaming processes live data streams in real-time.  \n",
        "This example demonstrates **real-time word count** using a **socket stream**.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Step 1: Start a Socket Text Stream\n",
        "\n",
        "Run this in a separate terminal:\n",
        "\n",
        "```bash\n",
        "nc -lk 9999\n",
        "````\n",
        "\n",
        "> This command starts a simple TCP server on port **9999**\n",
        "> You can type text lines here, which Spark will read in real-time.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Step 2: Spark Streaming Word Count Script\n",
        "\n",
        "Create a Spark Streaming application (`WordCountStreaming.scala`):\n",
        "\n",
        "```scala\n",
        "import org.apache.spark.SparkConf\n",
        "import org.apache.spark.streaming.{Seconds, StreamingContext}\n",
        "\n",
        "object WordCountStreaming {\n",
        "  def main(args: Array[String]): Unit = {\n",
        "\n",
        "    val conf = new SparkConf().setAppName(\"RealTimeWordCount\").setMaster(\"local[*]\")\n",
        "    val ssc = new StreamingContext(conf, Seconds(2))\n",
        "\n",
        "    // Connect to socket stream\n",
        "    val lines = ssc.socketTextStream(\"localhost\", 9999)\n",
        "\n",
        "    // Split lines into words\n",
        "    val words = lines.flatMap(_.split(\" \"))\n",
        "\n",
        "    // Map each word to (word, 1)\n",
        "    val wordPairs = words.map(word => (word, 1))\n",
        "\n",
        "    // Reduce by key (word count)\n",
        "    val wordCounts = wordPairs.reduceByKey(_ + _)\n",
        "\n",
        "    // Print results\n",
        "    wordCounts.print()\n",
        "\n",
        "    ssc.start()\n",
        "    ssc.awaitTermination()\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ñ∂Ô∏è Step 3: Run the Spark Streaming App\n",
        "\n",
        "```bash\n",
        "spark-submit --class WordCountStreaming wordcountstreaming.jar\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üî• Live Output Example\n",
        "\n",
        "If you type this in the `nc` terminal:\n",
        "\n",
        "```\n",
        "hello spark\n",
        "hello world\n",
        "```\n",
        "\n",
        "You will see output like:\n",
        "\n",
        "```\n",
        "-------------------------------------------\n",
        "Time: 2026-01-20 10:00:02\n",
        "-------------------------------------------\n",
        "(hello,2)\n",
        "(spark,1)\n",
        "(world,1)\n",
        "```\n"
      ],
      "metadata": {
        "id": "i4fIX5U_E2G5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PySpark"
      ],
      "metadata": {
        "id": "LU3at1P8Hmp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Real-Time Word Count Simulation in Colab\n",
        "# Fully self-contained, no files or sockets\n",
        "# ================================\n",
        "\n",
        "!pip install pyspark -q\n",
        "\n",
        "import time\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode, split, col\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"ColabStreamingWordCount\").getOrCreate()\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")\n",
        "\n",
        "# Predefined streaming data\n",
        "stream_data = [\n",
        "    \"hello spark\",\n",
        "    \"hello colab spark\",\n",
        "    \"spark streaming in colab\",\n",
        "    \"real time word count example\",\n",
        "    \"spark spark hello\"\n",
        "]\n",
        "\n",
        "# Define schema for cumulative DataFrame\n",
        "schema = StructType([\n",
        "    StructField(\"word\", StringType(), True),\n",
        "    StructField(\"count\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "# Create empty cumulative DataFrame with schema\n",
        "cumulative_counts = spark.createDataFrame([], schema)\n",
        "\n",
        "# Process each \"batch\" to simulate streaming\n",
        "for batch_num, line in enumerate(stream_data, 1):\n",
        "    # Create DataFrame for current batch\n",
        "    batch_df = spark.createDataFrame([(line,)], [\"value\"])\n",
        "\n",
        "    # Split line into words\n",
        "    words_df = batch_df.select(explode(split(col(\"value\"), \" \")).alias(\"word\"))\n",
        "\n",
        "    # Count words in this batch\n",
        "    batch_counts = words_df.groupBy(\"word\").count()\n",
        "\n",
        "    # Merge with cumulative counts\n",
        "    if cumulative_counts.count() == 0:\n",
        "        cumulative_counts = batch_counts\n",
        "    else:\n",
        "        cumulative_counts = cumulative_counts.union(batch_counts) \\\n",
        "            .groupBy(\"word\") \\\n",
        "            .sum(\"count\") \\\n",
        "            .withColumnRenamed(\"sum(count)\", \"count\")\n",
        "\n",
        "    # Display cumulative counts\n",
        "    print(f\"\\n--- Batch {batch_num} ---\")\n",
        "    cumulative_counts.show()\n",
        "\n",
        "    # Wait 2 seconds to simulate streaming\n",
        "    time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCDsGPSPHb83",
        "outputId": "23c395c0-f9fa-4af3-cab0-05b128896a8c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Batch 1 ---\n",
            "+-----+-----+\n",
            "| word|count|\n",
            "+-----+-----+\n",
            "|hello|    1|\n",
            "|spark|    1|\n",
            "+-----+-----+\n",
            "\n",
            "\n",
            "--- Batch 2 ---\n",
            "+-----+-----+\n",
            "| word|count|\n",
            "+-----+-----+\n",
            "|hello|    2|\n",
            "|spark|    2|\n",
            "|colab|    1|\n",
            "+-----+-----+\n",
            "\n",
            "\n",
            "--- Batch 3 ---\n",
            "+---------+-----+\n",
            "|     word|count|\n",
            "+---------+-----+\n",
            "|    hello|    2|\n",
            "|    spark|    3|\n",
            "|    colab|    2|\n",
            "|       in|    1|\n",
            "|streaming|    1|\n",
            "+---------+-----+\n",
            "\n",
            "\n",
            "--- Batch 4 ---\n",
            "+---------+-----+\n",
            "|     word|count|\n",
            "+---------+-----+\n",
            "|       in|    1|\n",
            "|    hello|    2|\n",
            "|streaming|    1|\n",
            "|    spark|    3|\n",
            "|    colab|    2|\n",
            "|  example|    1|\n",
            "|    count|    1|\n",
            "|     real|    1|\n",
            "|     word|    1|\n",
            "|     time|    1|\n",
            "+---------+-----+\n",
            "\n",
            "\n",
            "--- Batch 5 ---\n",
            "+---------+-----+\n",
            "|     word|count|\n",
            "+---------+-----+\n",
            "|  example|    1|\n",
            "|       in|    1|\n",
            "|    hello|    3|\n",
            "|    count|    1|\n",
            "|streaming|    1|\n",
            "|     real|    1|\n",
            "|    spark|    5|\n",
            "|     word|    1|\n",
            "|    colab|    2|\n",
            "|     time|    1|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}